{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exposed-chassis",
   "metadata": {},
   "source": [
    "# K - Nearest Neighbours(K-NN) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "natural-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfactory-riding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0     63    1   3       145   233    1        0      150      0      2.3   \n",
      "1     37    1   2       130   250    0        1      187      0      3.5   \n",
      "2     41    0   1       130   204    0        0      172      0      1.4   \n",
      "3     56    1   1       120   236    0        1      178      0      0.8   \n",
      "4     57    0   0       120   354    0        1      163      1      0.6   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "298   57    0   0       140   241    0        1      123      1      0.2   \n",
      "299   45    1   3       110   264    0        1      132      0      1.2   \n",
      "300   68    1   0       144   193    1        1      141      0      3.4   \n",
      "301   57    1   0       130   131    0        1      115      1      1.2   \n",
      "302   57    0   1       130   236    0        0      174      0      0.0   \n",
      "\n",
      "     slope  ca  thal  target  \n",
      "0        0   0     1       1  \n",
      "1        0   0     2       1  \n",
      "2        2   0     2       1  \n",
      "3        2   0     2       1  \n",
      "4        2   0     2       1  \n",
      "..     ...  ..   ...     ...  \n",
      "298      1   0     3       0  \n",
      "299      1   0     3       0  \n",
      "300      1   2     3       0  \n",
      "301      1   1     3       0  \n",
      "302      1   1     2       0  \n",
      "\n",
      "[303 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('heart.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attached-joining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forced-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expressed-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "referenced-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "variable-convergence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['slope'],df['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lined-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "----------------------------------------------------------------------\n",
      "[[ 0.  1. 63. ...  0.  0.  1.]\n",
      " [ 0.  1. 37. ...  0.  0.  2.]\n",
      " [ 1.  0. 41. ...  2.  0.  2.]\n",
      " ...\n",
      " [ 0.  1. 68. ...  1.  2.  3.]\n",
      " [ 0.  1. 57. ...  1.  1.  3.]\n",
      " [ 1.  0. 57. ...  1.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "# Encoding the categorical column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],\n",
    "                      remainder='passthrough')\n",
    "x = ct.fit_transform(x)\n",
    "print('----------------------------------------------------------------------')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "younger-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. 63.  3. ...  0.  0.  1.]\n",
      " [ 1. 37.  2. ...  0.  0.  2.]\n",
      " [ 0. 41.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [ 1. 68.  0. ...  1.  2.  3.]\n",
      " [ 1. 57.  0. ...  1.  1.  3.]\n",
      " [ 0. 57.  1. ...  1.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# copying x into x_copy while removing the dummy variable\n",
    "x_copy = x[:,1:]\n",
    "print(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rolled-objective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# now to complete the euqation(y = a1x1 + a2x2 + ..... + anxn + b) \n",
    "# we need to add the constant column\n",
    "b = np.ones((303,1),dtype=float)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hidden-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1. 63. ...  0.  0.  1.]\n",
      " [ 1.  1. 37. ...  0.  0.  2.]\n",
      " [ 1.  0. 41. ...  2.  0.  2.]\n",
      " ...\n",
      " [ 1.  1. 68. ...  1.  2.  3.]\n",
      " [ 1.  1. 57. ...  1.  1.  3.]\n",
      " [ 1.  0. 57. ...  1.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# if we are adding two np arrays column wise we put axis = 1\n",
    "# and if we add 2 np arrays rowwise we put axis = 0\n",
    "x_copy = np.append(arr=b,values=x_copy,axis=1)\n",
    "print(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interesting-optimization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   23.85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.49e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th> <td> -108.28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   244.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   289</td>      <th>  BIC:               </th> <td>   296.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8289</td> <td>    0.293</td> <td>    2.830</td> <td> 0.005</td> <td>    0.252</td> <td>    1.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1960</td> <td>    0.047</td> <td>   -4.157</td> <td> 0.000</td> <td>   -0.289</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0008</td> <td>    0.003</td> <td>   -0.304</td> <td> 0.761</td> <td>   -0.006</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1127</td> <td>    0.022</td> <td>    5.036</td> <td> 0.000</td> <td>    0.069</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0020</td> <td>    0.001</td> <td>   -1.583</td> <td> 0.114</td> <td>   -0.004</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0004</td> <td>    0.000</td> <td>   -0.838</td> <td> 0.403</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0174</td> <td>    0.060</td> <td>    0.291</td> <td> 0.771</td> <td>   -0.100</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0498</td> <td>    0.040</td> <td>    1.249</td> <td> 0.213</td> <td>   -0.029</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0030</td> <td>    0.001</td> <td>    2.671</td> <td> 0.008</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.1440</td> <td>    0.051</td> <td>   -2.804</td> <td> 0.005</td> <td>   -0.245</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0588</td> <td>    0.023</td> <td>   -2.564</td> <td> 0.011</td> <td>   -0.104</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0790</td> <td>    0.042</td> <td>    1.863</td> <td> 0.063</td> <td>   -0.004</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.1006</td> <td>    0.022</td> <td>   -4.603</td> <td> 0.000</td> <td>   -0.144</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.1190</td> <td>    0.036</td> <td>   -3.339</td> <td> 0.001</td> <td>   -0.189</td> <td>   -0.049</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.751</td> <th>  Durbin-Watson:     </th> <td>   1.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.034</td> <th>  Jarque-Bera (JB):  </th> <td>   6.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.361</td> <th>  Prob(JB):          </th> <td>  0.0308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.824</td> <th>  Cond. No.          </th> <td>4.68e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.68e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.518\n",
       "Model:                            OLS   Adj. R-squared:                  0.496\n",
       "Method:                 Least Squares   F-statistic:                     23.85\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):           1.49e-38\n",
       "Time:                        14:01:15   Log-Likelihood:                -108.28\n",
       "No. Observations:                 303   AIC:                             244.6\n",
       "Df Residuals:                     289   BIC:                             296.6\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8289      0.293      2.830      0.005       0.252       1.405\n",
       "x1            -0.1960      0.047     -4.157      0.000      -0.289      -0.103\n",
       "x2            -0.0008      0.003     -0.304      0.761      -0.006       0.004\n",
       "x3             0.1127      0.022      5.036      0.000       0.069       0.157\n",
       "x4            -0.0020      0.001     -1.583      0.114      -0.004       0.000\n",
       "x5            -0.0004      0.000     -0.838      0.403      -0.001       0.000\n",
       "x6             0.0174      0.060      0.291      0.771      -0.100       0.135\n",
       "x7             0.0498      0.040      1.249      0.213      -0.029       0.128\n",
       "x8             0.0030      0.001      2.671      0.008       0.001       0.005\n",
       "x9            -0.1440      0.051     -2.804      0.005      -0.245      -0.043\n",
       "x10           -0.0588      0.023     -2.564      0.011      -0.104      -0.014\n",
       "x11            0.0790      0.042      1.863      0.063      -0.004       0.162\n",
       "x12           -0.1006      0.022     -4.603      0.000      -0.144      -0.058\n",
       "x13           -0.1190      0.036     -3.339      0.001      -0.189      -0.049\n",
       "==============================================================================\n",
       "Omnibus:                        6.751   Durbin-Watson:                   1.032\n",
       "Prob(Omnibus):                  0.034   Jarque-Bera (JB):                6.958\n",
       "Skew:                          -0.361   Prob(JB):                       0.0308\n",
       "Kurtosis:                       2.824   Cond. No.                     4.68e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.68e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "capable-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we got the most significant column we can create a regression model\n",
    "#we will start by splitting x_opt and y into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "xo_tr,xo_te,yo_tr,yo_te = train_test_split(x_opt,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surrounded-chaos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4690443546615132\n"
     ]
    }
   ],
   "source": [
    "# creating the optimal model prediciting and checking the r2_Score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "lr_opt = LinearRegression()\n",
    "lr_opt.fit(xo_tr,yo_tr)\n",
    "yo_pr = lr_opt.predict(xo_te)\n",
    "print(r2_score(yo_te,yo_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "premium-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   25.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>2.98e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th> <td> -108.33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   242.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   290</td>      <th>  BIC:               </th> <td>   290.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8218</td> <td>    0.291</td> <td>    2.820</td> <td> 0.005</td> <td>    0.248</td> <td>    1.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1952</td> <td>    0.047</td> <td>   -4.154</td> <td> 0.000</td> <td>   -0.288</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0008</td> <td>    0.003</td> <td>   -0.287</td> <td> 0.775</td> <td>   -0.006</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1134</td> <td>    0.022</td> <td>    5.107</td> <td> 0.000</td> <td>    0.070</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0019</td> <td>    0.001</td> <td>   -1.560</td> <td> 0.120</td> <td>   -0.004</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0004</td> <td>    0.000</td> <td>   -0.843</td> <td> 0.400</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0493</td> <td>    0.040</td> <td>    1.238</td> <td> 0.217</td> <td>   -0.029</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0030</td> <td>    0.001</td> <td>    2.688</td> <td> 0.008</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.1432</td> <td>    0.051</td> <td>   -2.797</td> <td> 0.006</td> <td>   -0.244</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0593</td> <td>    0.023</td> <td>   -2.602</td> <td> 0.010</td> <td>   -0.104</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0780</td> <td>    0.042</td> <td>    1.849</td> <td> 0.065</td> <td>   -0.005</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0997</td> <td>    0.022</td> <td>   -4.613</td> <td> 0.000</td> <td>   -0.142</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.1196</td> <td>    0.036</td> <td>   -3.365</td> <td> 0.001</td> <td>   -0.190</td> <td>   -0.050</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.917</td> <th>  Durbin-Watson:     </th> <td>   1.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.031</td> <th>  Jarque-Bera (JB):  </th> <td>   7.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.365</td> <th>  Prob(JB):          </th> <td>  0.0282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.820</td> <th>  Cond. No.          </th> <td>4.66e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.66e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.517\n",
       "Model:                            OLS   Adj. R-squared:                  0.497\n",
       "Method:                 Least Squares   F-statistic:                     25.91\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):           2.98e-39\n",
       "Time:                        14:01:15   Log-Likelihood:                -108.33\n",
       "No. Observations:                 303   AIC:                             242.7\n",
       "Df Residuals:                     290   BIC:                             290.9\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8218      0.291      2.820      0.005       0.248       1.395\n",
       "x1            -0.1952      0.047     -4.154      0.000      -0.288      -0.103\n",
       "x2            -0.0008      0.003     -0.287      0.775      -0.006       0.005\n",
       "x3             0.1134      0.022      5.107      0.000       0.070       0.157\n",
       "x4            -0.0019      0.001     -1.560      0.120      -0.004       0.001\n",
       "x5            -0.0004      0.000     -0.843      0.400      -0.001       0.000\n",
       "x6             0.0493      0.040      1.238      0.217      -0.029       0.128\n",
       "x7             0.0030      0.001      2.688      0.008       0.001       0.005\n",
       "x8            -0.1432      0.051     -2.797      0.006      -0.244      -0.042\n",
       "x9            -0.0593      0.023     -2.602      0.010      -0.104      -0.014\n",
       "x10            0.0780      0.042      1.849      0.065      -0.005       0.161\n",
       "x11           -0.0997      0.022     -4.613      0.000      -0.142      -0.057\n",
       "x12           -0.1196      0.036     -3.365      0.001      -0.190      -0.050\n",
       "==============================================================================\n",
       "Omnibus:                        6.917   Durbin-Watson:                   1.033\n",
       "Prob(Omnibus):                  0.031   Jarque-Bera (JB):                7.134\n",
       "Skew:                          -0.365   Prob(JB):                       0.0282\n",
       "Kurtosis:                       2.820   Cond. No.                     4.66e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.66e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[0,1,2,3,4,5,7,8,9,10,11,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "requested-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>5.67e-40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th> <td> -108.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   240.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   291</td>      <th>  BIC:               </th> <td>   285.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7787</td> <td>    0.249</td> <td>    3.124</td> <td> 0.002</td> <td>    0.288</td> <td>    1.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1939</td> <td>    0.047</td> <td>   -4.153</td> <td> 0.000</td> <td>   -0.286</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1131</td> <td>    0.022</td> <td>    5.107</td> <td> 0.000</td> <td>    0.069</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0020</td> <td>    0.001</td> <td>   -1.678</td> <td> 0.094</td> <td>   -0.004</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0004</td> <td>    0.000</td> <td>   -0.906</td> <td> 0.366</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0500</td> <td>    0.040</td> <td>    1.259</td> <td> 0.209</td> <td>   -0.028</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0032</td> <td>    0.001</td> <td>    3.009</td> <td> 0.003</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.1421</td> <td>    0.051</td> <td>   -2.788</td> <td> 0.006</td> <td>   -0.242</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0595</td> <td>    0.023</td> <td>   -2.614</td> <td> 0.009</td> <td>   -0.104</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0778</td> <td>    0.042</td> <td>    1.848</td> <td> 0.066</td> <td>   -0.005</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1010</td> <td>    0.021</td> <td>   -4.771</td> <td> 0.000</td> <td>   -0.143</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.1198</td> <td>    0.035</td> <td>   -3.375</td> <td> 0.001</td> <td>   -0.190</td> <td>   -0.050</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.163</td> <th>  Durbin-Watson:     </th> <td>   1.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.028</td> <th>  Jarque-Bera (JB):  </th> <td>   7.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.373</td> <th>  Prob(JB):          </th> <td>  0.0247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.826</td> <th>  Cond. No.          </th> <td>3.94e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.94e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.517\n",
       "Model:                            OLS   Adj. R-squared:                  0.499\n",
       "Method:                 Least Squares   F-statistic:                     28.35\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):           5.67e-40\n",
       "Time:                        14:01:15   Log-Likelihood:                -108.37\n",
       "No. Observations:                 303   AIC:                             240.7\n",
       "Df Residuals:                     291   BIC:                             285.3\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7787      0.249      3.124      0.002       0.288       1.269\n",
       "x1            -0.1939      0.047     -4.153      0.000      -0.286      -0.102\n",
       "x2             0.1131      0.022      5.107      0.000       0.069       0.157\n",
       "x3            -0.0020      0.001     -1.678      0.094      -0.004       0.000\n",
       "x4            -0.0004      0.000     -0.906      0.366      -0.001       0.000\n",
       "x5             0.0500      0.040      1.259      0.209      -0.028       0.128\n",
       "x6             0.0032      0.001      3.009      0.003       0.001       0.005\n",
       "x7            -0.1421      0.051     -2.788      0.006      -0.242      -0.042\n",
       "x8            -0.0595      0.023     -2.614      0.009      -0.104      -0.015\n",
       "x9             0.0778      0.042      1.848      0.066      -0.005       0.161\n",
       "x10           -0.1010      0.021     -4.771      0.000      -0.143      -0.059\n",
       "x11           -0.1198      0.035     -3.375      0.001      -0.190      -0.050\n",
       "==============================================================================\n",
       "Omnibus:                        7.163   Durbin-Watson:                   1.032\n",
       "Prob(Omnibus):                  0.028   Jarque-Bera (JB):                7.400\n",
       "Skew:                          -0.373   Prob(JB):                       0.0247\n",
       "Kurtosis:                       2.826   Cond. No.                     3.94e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.94e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[0,1,3,4,5,7,8,9,10,11,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mediterranean-uniform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.47e-40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th> <td> -108.80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   239.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   292</td>      <th>  BIC:               </th> <td>   280.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7053</td> <td>    0.236</td> <td>    2.993</td> <td> 0.003</td> <td>    0.242</td> <td>    1.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1837</td> <td>    0.045</td> <td>   -4.055</td> <td> 0.000</td> <td>   -0.273</td> <td>   -0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1140</td> <td>    0.022</td> <td>    5.156</td> <td> 0.000</td> <td>    0.070</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0021</td> <td>    0.001</td> <td>   -1.758</td> <td> 0.080</td> <td>   -0.004</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0555</td> <td>    0.039</td> <td>    1.416</td> <td> 0.158</td> <td>   -0.022</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0031</td> <td>    0.001</td> <td>    2.981</td> <td> 0.003</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.1444</td> <td>    0.051</td> <td>   -2.835</td> <td> 0.005</td> <td>   -0.245</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0602</td> <td>    0.023</td> <td>   -2.646</td> <td> 0.009</td> <td>   -0.105</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0761</td> <td>    0.042</td> <td>    1.808</td> <td> 0.072</td> <td>   -0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.1019</td> <td>    0.021</td> <td>   -4.825</td> <td> 0.000</td> <td>   -0.144</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1235</td> <td>    0.035</td> <td>   -3.505</td> <td> 0.001</td> <td>   -0.193</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.375</td> <th>  Durbin-Watson:     </th> <td>   1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.025</td> <th>  Jarque-Bera (JB):  </th> <td>   7.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.383</td> <th>  Prob(JB):          </th> <td>  0.0221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.867</td> <th>  Cond. No.          </th> <td>2.33e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.33e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.516\n",
       "Model:                            OLS   Adj. R-squared:                  0.499\n",
       "Method:                 Least Squares   F-statistic:                     31.12\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):           1.47e-40\n",
       "Time:                        14:01:15   Log-Likelihood:                -108.80\n",
       "No. Observations:                 303   AIC:                             239.6\n",
       "Df Residuals:                     292   BIC:                             280.4\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7053      0.236      2.993      0.003       0.242       1.169\n",
       "x1            -0.1837      0.045     -4.055      0.000      -0.273      -0.095\n",
       "x2             0.1140      0.022      5.156      0.000       0.070       0.157\n",
       "x3            -0.0021      0.001     -1.758      0.080      -0.004       0.000\n",
       "x4             0.0555      0.039      1.416      0.158      -0.022       0.133\n",
       "x5             0.0031      0.001      2.981      0.003       0.001       0.005\n",
       "x6            -0.1444      0.051     -2.835      0.005      -0.245      -0.044\n",
       "x7            -0.0602      0.023     -2.646      0.009      -0.105      -0.015\n",
       "x8             0.0761      0.042      1.808      0.072      -0.007       0.159\n",
       "x9            -0.1019      0.021     -4.825      0.000      -0.144      -0.060\n",
       "x10           -0.1235      0.035     -3.505      0.001      -0.193      -0.054\n",
       "==============================================================================\n",
       "Omnibus:                        7.375   Durbin-Watson:                   1.031\n",
       "Prob(Omnibus):                  0.025   Jarque-Bera (JB):                7.623\n",
       "Skew:                          -0.383   Prob(JB):                       0.0221\n",
       "Kurtosis:                       2.867   Cond. No.                     2.33e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.33e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[0,1,3,4,7,8,9,10,11,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "married-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>6.44e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th> <td> -109.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   239.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   293</td>      <th>  BIC:               </th> <td>   276.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7555</td> <td>    0.233</td> <td>    3.237</td> <td> 0.001</td> <td>    0.296</td> <td>    1.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1874</td> <td>    0.045</td> <td>   -4.136</td> <td> 0.000</td> <td>   -0.277</td> <td>   -0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1147</td> <td>    0.022</td> <td>    5.182</td> <td> 0.000</td> <td>    0.071</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0023</td> <td>    0.001</td> <td>   -1.916</td> <td> 0.056</td> <td>   -0.005</td> <td> 6.18e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0031</td> <td>    0.001</td> <td>    2.955</td> <td> 0.003</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.1467</td> <td>    0.051</td> <td>   -2.878</td> <td> 0.004</td> <td>   -0.247</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0593</td> <td>    0.023</td> <td>   -2.604</td> <td> 0.010</td> <td>   -0.104</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0804</td> <td>    0.042</td> <td>    1.912</td> <td> 0.057</td> <td>   -0.002</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.1035</td> <td>    0.021</td> <td>   -4.895</td> <td> 0.000</td> <td>   -0.145</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.1222</td> <td>    0.035</td> <td>   -3.463</td> <td> 0.001</td> <td>   -0.192</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.829</td> <th>  Durbin-Watson:     </th> <td>   1.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.033</td> <th>  Jarque-Bera (JB):  </th> <td>   7.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.369</td> <th>  Prob(JB):          </th> <td>  0.0301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.906</td> <th>  Cond. No.          </th> <td>2.31e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.31e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.513\n",
       "Model:                            OLS   Adj. R-squared:                  0.498\n",
       "Method:                 Least Squares   F-statistic:                     34.24\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):           6.44e-41\n",
       "Time:                        14:01:15   Log-Likelihood:                -109.83\n",
       "No. Observations:                 303   AIC:                             239.7\n",
       "Df Residuals:                     293   BIC:                             276.8\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7555      0.233      3.237      0.001       0.296       1.215\n",
       "x1            -0.1874      0.045     -4.136      0.000      -0.277      -0.098\n",
       "x2             0.1147      0.022      5.182      0.000       0.071       0.158\n",
       "x3            -0.0023      0.001     -1.916      0.056      -0.005    6.18e-05\n",
       "x4             0.0031      0.001      2.955      0.003       0.001       0.005\n",
       "x5            -0.1467      0.051     -2.878      0.004      -0.247      -0.046\n",
       "x6            -0.0593      0.023     -2.604      0.010      -0.104      -0.014\n",
       "x7             0.0804      0.042      1.912      0.057      -0.002       0.163\n",
       "x8            -0.1035      0.021     -4.895      0.000      -0.145      -0.062\n",
       "x9            -0.1222      0.035     -3.463      0.001      -0.192      -0.053\n",
       "==============================================================================\n",
       "Omnibus:                        6.829   Durbin-Watson:                   1.032\n",
       "Prob(Omnibus):                  0.033   Jarque-Bera (JB):                7.006\n",
       "Skew:                          -0.369   Prob(JB):                       0.0301\n",
       "Kurtosis:                       2.906   Cond. No.                     2.31e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.31e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[0,1,3,4,8,9,10,11,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "modern-kitchen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   37.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>5.98e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th> <td> -111.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   241.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   294</td>      <th>  BIC:               </th> <td>   274.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8221</td> <td>    0.232</td> <td>    3.547</td> <td> 0.000</td> <td>    0.366</td> <td>    1.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1852</td> <td>    0.046</td> <td>   -4.070</td> <td> 0.000</td> <td>   -0.275</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1136</td> <td>    0.022</td> <td>    5.112</td> <td> 0.000</td> <td>    0.070</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0023</td> <td>    0.001</td> <td>   -1.945</td> <td> 0.053</td> <td>   -0.005</td> <td> 2.74e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0036</td> <td>    0.001</td> <td>    3.482</td> <td> 0.001</td> <td>    0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.1521</td> <td>    0.051</td> <td>   -2.975</td> <td> 0.003</td> <td>   -0.253</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0811</td> <td>    0.020</td> <td>   -4.095</td> <td> 0.000</td> <td>   -0.120</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0997</td> <td>    0.021</td> <td>   -4.715</td> <td> 0.000</td> <td>   -0.141</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.1209</td> <td>    0.035</td> <td>   -3.413</td> <td> 0.001</td> <td>   -0.191</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.546</td> <th>  Durbin-Watson:     </th> <td>   1.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.023</td> <th>  Jarque-Bera (JB):  </th> <td>   7.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.387</td> <th>  Prob(JB):          </th> <td>  0.0201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.859</td> <th>  Cond. No.          </th> <td>2.28e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.28e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.507\n",
       "Model:                            OLS   Adj. R-squared:                  0.493\n",
       "Method:                 Least Squares   F-statistic:                     37.72\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):           5.98e-41\n",
       "Time:                        14:01:15   Log-Likelihood:                -111.71\n",
       "No. Observations:                 303   AIC:                             241.4\n",
       "Df Residuals:                     294   BIC:                             274.8\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8221      0.232      3.547      0.000       0.366       1.278\n",
       "x1            -0.1852      0.046     -4.070      0.000      -0.275      -0.096\n",
       "x2             0.1136      0.022      5.112      0.000       0.070       0.157\n",
       "x3            -0.0023      0.001     -1.945      0.053      -0.005    2.74e-05\n",
       "x4             0.0036      0.001      3.482      0.001       0.002       0.006\n",
       "x5            -0.1521      0.051     -2.975      0.003      -0.253      -0.051\n",
       "x6            -0.0811      0.020     -4.095      0.000      -0.120      -0.042\n",
       "x7            -0.0997      0.021     -4.715      0.000      -0.141      -0.058\n",
       "x8            -0.1209      0.035     -3.413      0.001      -0.191      -0.051\n",
       "==============================================================================\n",
       "Omnibus:                        7.546   Durbin-Watson:                   1.019\n",
       "Prob(Omnibus):                  0.023   Jarque-Bera (JB):                7.811\n",
       "Skew:                          -0.387   Prob(JB):                       0.0201\n",
       "Kurtosis:                       2.859   Cond. No.                     2.28e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[0,1,3,4,8,9,10,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "color-stadium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   42.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>5.58e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th> <td> -113.65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th> <td>   243.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   295</td>      <th>  BIC:               </th> <td>   273.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5365</td> <td>    0.180</td> <td>    2.977</td> <td> 0.003</td> <td>    0.182</td> <td>    0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1769</td> <td>    0.046</td> <td>   -3.886</td> <td> 0.000</td> <td>   -0.266</td> <td>   -0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1093</td> <td>    0.022</td> <td>    4.919</td> <td> 0.000</td> <td>    0.066</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0035</td> <td>    0.001</td> <td>    3.423</td> <td> 0.001</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.1576</td> <td>    0.051</td> <td>   -3.074</td> <td> 0.002</td> <td>   -0.259</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0875</td> <td>    0.020</td> <td>   -4.462</td> <td> 0.000</td> <td>   -0.126</td> <td>   -0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.1030</td> <td>    0.021</td> <td>   -4.868</td> <td> 0.000</td> <td>   -0.145</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.1235</td> <td>    0.036</td> <td>   -3.471</td> <td> 0.001</td> <td>   -0.193</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.758</td> <th>  Durbin-Watson:     </th> <td>   1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.021</td> <th>  Jarque-Bera (JB):  </th> <td>   7.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.396</td> <th>  Prob(JB):          </th> <td>  0.0183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.918</td> <th>  Cond. No.          </th> <td>1.34e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.34e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.500\n",
       "Model:                            OLS   Adj. R-squared:                  0.488\n",
       "Method:                 Least Squares   F-statistic:                     42.17\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):           5.58e-41\n",
       "Time:                        14:01:15   Log-Likelihood:                -113.65\n",
       "No. Observations:                 303   AIC:                             243.3\n",
       "Df Residuals:                     295   BIC:                             273.0\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5365      0.180      2.977      0.003       0.182       0.891\n",
       "x1            -0.1769      0.046     -3.886      0.000      -0.266      -0.087\n",
       "x2             0.1093      0.022      4.919      0.000       0.066       0.153\n",
       "x3             0.0035      0.001      3.423      0.001       0.001       0.006\n",
       "x4            -0.1576      0.051     -3.074      0.002      -0.259      -0.057\n",
       "x5            -0.0875      0.020     -4.462      0.000      -0.126      -0.049\n",
       "x6            -0.1030      0.021     -4.868      0.000      -0.145      -0.061\n",
       "x7            -0.1235      0.036     -3.471      0.001      -0.193      -0.053\n",
       "==============================================================================\n",
       "Omnibus:                        7.758   Durbin-Watson:                   1.015\n",
       "Prob(Omnibus):                  0.021   Jarque-Bera (JB):                7.998\n",
       "Skew:                          -0.396   Prob(JB):                       0.0183\n",
       "Kurtosis:                       2.918   Cond. No.                     1.34e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.34e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[0,1,3,8,9,10,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alternate-afternoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   138.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th>          <td>2.56e-89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th>          <td> -118.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th>          <td>   250.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   296</td>      <th>  BIC:               </th>          <td>   276.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.1706</td> <td>    0.046</td> <td>   -3.705</td> <td> 0.000</td> <td>   -0.261</td> <td>   -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.1129</td> <td>    0.022</td> <td>    5.024</td> <td> 0.000</td> <td>    0.069</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0062</td> <td>    0.001</td> <td>   12.091</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -0.1178</td> <td>    0.050</td> <td>   -2.349</td> <td> 0.020</td> <td>   -0.217</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>   -0.0745</td> <td>    0.019</td> <td>   -3.846</td> <td> 0.000</td> <td>   -0.113</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th> <td>   -0.0941</td> <td>    0.021</td> <td>   -4.431</td> <td> 0.000</td> <td>   -0.136</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th> <td>   -0.0847</td> <td>    0.034</td> <td>   -2.524</td> <td> 0.012</td> <td>   -0.151</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.273</td> <th>  Durbin-Watson:     </th> <td>   1.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.026</td> <th>  Jarque-Bera (JB):  </th> <td>   7.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.383</td> <th>  Prob(JB):          </th> <td>  0.0244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.951</td> <th>  Cond. No.          </th> <td>    382.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.766\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.760\n",
       "Method:                 Least Squares   F-statistic:                              138.0\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):                    2.56e-89\n",
       "Time:                        14:01:15   Log-Likelihood:                         -118.13\n",
       "No. Observations:                 303   AIC:                                      250.3\n",
       "Df Residuals:                     296   BIC:                                      276.3\n",
       "Df Model:                           7                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.1706      0.046     -3.705      0.000      -0.261      -0.080\n",
       "x2             0.1129      0.022      5.024      0.000       0.069       0.157\n",
       "x3             0.0062      0.001     12.091      0.000       0.005       0.007\n",
       "x4            -0.1178      0.050     -2.349      0.020      -0.217      -0.019\n",
       "x5            -0.0745      0.019     -3.846      0.000      -0.113      -0.036\n",
       "x6            -0.0941      0.021     -4.431      0.000      -0.136      -0.052\n",
       "x7            -0.0847      0.034     -2.524      0.012      -0.151      -0.019\n",
       "==============================================================================\n",
       "Omnibus:                        7.273   Durbin-Watson:                   1.042\n",
       "Prob(Omnibus):                  0.026   Jarque-Bera (JB):                7.429\n",
       "Skew:                          -0.383   Prob(JB):                       0.0244\n",
       "Kurtosis:                       2.951   Cond. No.                         382.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[1,3,8,9,10,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "altered-blues",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   157.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th>          <td>2.96e-89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th>          <td> -120.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th>          <td>   253.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   297</td>      <th>  BIC:               </th>          <td>   276.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.1833</td> <td>    0.046</td> <td>   -3.975</td> <td> 0.000</td> <td>   -0.274</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.1289</td> <td>    0.022</td> <td>    5.966</td> <td> 0.000</td> <td>    0.086</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0062</td> <td>    0.001</td> <td>   12.100</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -0.0847</td> <td>    0.019</td> <td>   -4.451</td> <td> 0.000</td> <td>   -0.122</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>   -0.0934</td> <td>    0.021</td> <td>   -4.367</td> <td> 0.000</td> <td>   -0.135</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th> <td>   -0.1022</td> <td>    0.033</td> <td>   -3.103</td> <td> 0.002</td> <td>   -0.167</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.202</td> <th>  Durbin-Watson:     </th> <td>   1.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.045</td> <th>  Jarque-Bera (JB):  </th> <td>   6.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.346</td> <th>  Prob(JB):          </th> <td>  0.0413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.835</td> <th>  Cond. No.          </th> <td>    342.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.761\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.756\n",
       "Method:                 Least Squares   F-statistic:                              157.7\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):                    2.96e-89\n",
       "Time:                        14:01:15   Log-Likelihood:                         -120.93\n",
       "No. Observations:                 303   AIC:                                      253.9\n",
       "Df Residuals:                     297   BIC:                                      276.1\n",
       "Df Model:                           6                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.1833      0.046     -3.975      0.000      -0.274      -0.093\n",
       "x2             0.1289      0.022      5.966      0.000       0.086       0.171\n",
       "x3             0.0062      0.001     12.100      0.000       0.005       0.007\n",
       "x4            -0.0847      0.019     -4.451      0.000      -0.122      -0.047\n",
       "x5            -0.0934      0.021     -4.367      0.000      -0.135      -0.051\n",
       "x6            -0.1022      0.033     -3.103      0.002      -0.167      -0.037\n",
       "==============================================================================\n",
       "Omnibus:                        6.202   Durbin-Watson:                   1.003\n",
       "Prob(Omnibus):                  0.045   Jarque-Bera (JB):                6.375\n",
       "Skew:                          -0.346   Prob(JB):                       0.0413\n",
       "Kurtosis:                       2.835   Cond. No.                         342.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[1,3,8,10,12,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "precise-shannon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   182.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th>          <td>2.33e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th>          <td> -125.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th>          <td>   261.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   298</td>      <th>  BIC:               </th>          <td>   280.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.2172</td> <td>    0.045</td> <td>   -4.781</td> <td> 0.000</td> <td>   -0.307</td> <td>   -0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.1384</td> <td>    0.022</td> <td>    6.385</td> <td> 0.000</td> <td>    0.096</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0049</td> <td>    0.000</td> <td>   16.034</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -0.1030</td> <td>    0.018</td> <td>   -5.610</td> <td> 0.000</td> <td>   -0.139</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>   -0.1031</td> <td>    0.021</td> <td>   -4.802</td> <td> 0.000</td> <td>   -0.145</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.384</td> <th>  Durbin-Watson:     </th> <td>   0.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.025</td> <th>  Jarque-Bera (JB):  </th> <td>   7.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.351</td> <th>  Prob(JB):          </th> <td>  0.0249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.697</td> <th>  Cond. No.          </th> <td>    325.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.753\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.749\n",
       "Method:                 Least Squares   F-statistic:                              182.1\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):                    2.33e-88\n",
       "Time:                        14:01:15   Log-Likelihood:                         -125.76\n",
       "No. Observations:                 303   AIC:                                      261.5\n",
       "Df Residuals:                     298   BIC:                                      280.1\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.2172      0.045     -4.781      0.000      -0.307      -0.128\n",
       "x2             0.1384      0.022      6.385      0.000       0.096       0.181\n",
       "x3             0.0049      0.000     16.034      0.000       0.004       0.006\n",
       "x4            -0.1030      0.018     -5.610      0.000      -0.139      -0.067\n",
       "x5            -0.1031      0.021     -4.802      0.000      -0.145      -0.061\n",
       "==============================================================================\n",
       "Omnibus:                        7.384   Durbin-Watson:                   0.938\n",
       "Prob(Omnibus):                  0.025   Jarque-Bera (JB):                7.385\n",
       "Skew:                          -0.351   Prob(JB):                       0.0249\n",
       "Kurtosis:                       2.697   Cond. No.                         325.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to get down to 2 features we remove the extra features and proceed with svm algorithm\n",
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[1,3,8,10,12]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "arctic-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   210.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 09 Apr 2021</td> <th>  Prob (F-statistic):</th>          <td>6.73e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:01:15</td>     <th>  Log-Likelihood:    </th>          <td> -205.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   303</td>      <th>  AIC:               </th>          <td>   414.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   301</td>      <th>  BIC:               </th>          <td>   422.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.2653</td> <td>    0.025</td> <td>   10.581</td> <td> 0.000</td> <td>    0.216</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.1028</td> <td>    0.015</td> <td>    6.945</td> <td> 0.000</td> <td>    0.074</td> <td>    0.132</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.701</td> <th>  Durbin-Watson:     </th> <td>   0.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>   6.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.149</td> <th>  Prob(JB):          </th> <td>  0.0314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.323</td> <th>  Cond. No.          </th> <td>    2.55</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.583\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.580\n",
       "Method:                 Least Squares   F-statistic:                              210.4\n",
       "Date:                Fri, 09 Apr 2021   Prob (F-statistic):                    6.73e-58\n",
       "Time:                        14:01:15   Log-Likelihood:                         -205.34\n",
       "No. Observations:                 303   AIC:                                      414.7\n",
       "Df Residuals:                     301   BIC:                                      422.1\n",
       "Df Model:                           2                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.2653      0.025     10.581      0.000       0.216       0.315\n",
       "x2             0.1028      0.015      6.945      0.000       0.074       0.132\n",
       "==============================================================================\n",
       "Omnibus:                       13.701   Durbin-Watson:                   0.564\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                6.921\n",
       "Skew:                          -0.149   Prob(JB):                       0.0314\n",
       "Kurtosis:                       2.323   Cond. No.                         2.55\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking feature 3 & 13 \n",
    "import statsmodels.api as sm\n",
    "# creating another variable to collect the most optimal columns of x\n",
    "# we are performing manual BE\n",
    "x_opt = np.array(x_copy[:,[3,13]],dtype = float)\n",
    "stat = sm.OLS(endog=y,exog=x_opt).fit()\n",
    "stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "internal-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we got the most significant column we can create a regression model\n",
    "#we will start by splitting x_opt and y into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "xo_tr,xo_te,yo_tr,yo_te = train_test_split(x_opt,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "elementary-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35454698682309893\n"
     ]
    }
   ],
   "source": [
    "# creating the optimal model prediciting and checking the r2_Score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_opt = LinearRegression()\n",
    "lr_opt.fit(xo_tr,yo_tr)\n",
    "yo_pr = lr_opt.predict(xo_te)\n",
    "print(r2_score(yo_te,yo_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "pursuant-supplement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=7,metric='minkowski',p=2)\n",
    "classifier.fit(xo_tr,yo_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "contemporary-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]]\n",
      "0.7540983606557377\n"
     ]
    }
   ],
   "source": [
    "# predict the output and calculate the accuracy score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "y_pred = classifier.predict(xo_te)\n",
    "print(np.concatenate((yo_te.reshape(len(yo_te),1),\n",
    "                      y_pred.reshape(len(y_pred),1)),axis=1))\n",
    "print(accuracy_score(yo_te,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "intimate-quarter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the confusion matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix,plot_decision_regions\n",
    "cm = confusion_matrix(yo_te,y_pred)\n",
    "plot_confusion_matrix(cm) # we give the name of the confusion matrix variable\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "level-beijing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_regions(X=xo_te,y=yo_te,clf=classifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-production",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "## 1) In this code, we first do the necessary eda and data preprocessing by checking for the missing values. The dataset contains no empty values.\n",
    "## 2) We check for the categorical column and encode them.\n",
    "## 3) We prepare the x and y for backward elimination to remove the extra features from the    dataset. Thus, we reduce the dimensionality to 2 features only in order to escape for the filler feature values during plotting of decision regions of confusion matrix.\n",
    "## 4) After backward eliminating manually, we train the dataset using the test values.\n",
    "## 5) We predict the accuracy score of the knn classification model using knn classifier which is 81.48%\n",
    "## 6) Then, we plot the confusion matrix for the same dataset values as above.\n",
    "## 7) Atlast, we plot the decision regions for 0's and 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-mobile",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
